import feedparser
import time
import os
from datetime import datetime, timedelta
from urllib.parse import quote

# --- ì„¤ì • ë¶€ë¶„ ---

# ìˆ˜ì§‘ì„ ì›í•˜ëŠ” ì–¸ë¡ ì‚¬ ëª©ë¡
target_sources = [
    'MBCë‰´ìŠ¤', 'ì—°í•©ë‰´ìŠ¤', 'ì¡°ì„ ì¼ë³´', 'ë‰´ìŠ¤1', 'JTBC News', 
    'ì¤‘ì•™ì¼ë³´', 'SBS ë‰´ìŠ¤', 'YTN', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸', 
    'ì˜¤ë§ˆì´ë‰´ìŠ¤', 'í•œêµ­ê²½ì œ'
]

# ìˆ˜ì§‘í•  ë‰´ìŠ¤ì˜ ëŒ€ë¶„ë¥˜ ë° ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ëª©ë¡
categories = {
    'ì •ì¹˜': ['ëŒ€í†µë ¹ì‹¤', 'êµ­íšŒ', 'ì •ë‹¹', 'í–‰ì •', 'ì™¸êµ', 'êµ­ë°©/ë¶í•œ'],
    'ê²½ì œ': ['ê¸ˆìœµ/ì¦ê¶Œ', 'ì‚°ì—…/ì¬ê³„', 'ì¤‘ê¸°/ë²¤ì²˜', 'ë¶€ë™ì‚°', 'ê¸€ë¡œë²Œ', 'ìƒí™œ'],
    'ì‚¬íšŒ': ['ì‚¬ê±´ì‚¬ê³ ', 'êµìœ¡', 'ë…¸ë™', 'ì–¸ë¡ ', 'í™˜ê²½', 'ì¸ê¶Œ/ë³µì§€', 'ì‹í’ˆ/ì˜ë£Œ', 'ì§€ì—­', 'ì¸ë¬¼'],
    'IT_ê³¼í•™': ['ëª¨ë°”ì¼', 'ì¸í„°ë„·/SNS', 'í†µì‹ /ë‰´ë¯¸ë””ì–´', 'IT', 'ë³´ì•ˆ/í•´í‚¹', 'ì»´í“¨í„°', 'ê²Œì„/ë¦¬ë·°', 'ê³¼í•™'],
    'ìƒí™œ_ë¬¸í™”': ['ê±´ê°•', 'ìë™ì°¨', 'ì—¬í–‰/ë ˆì €', 'ìŒì‹/ë§›ì§‘', 'íŒ¨ì…˜/ë·°í‹°', 'ê³µì—°/ì „ì‹œ', 'ì±…', 'ì¢…êµ', 'ë‚ ì”¨', 'ìƒí™œ'],
    'ì„¸ê³„': ['ì•„ì‹œì•„/í˜¸ì£¼', 'ë¯¸êµ­/ì¤‘ë‚¨ë¯¸', 'ìœ ëŸ½', 'ì¤‘ë™/ì•„í”„ë¦¬ì¹´', 'ì„¸ê³„']
}

# ê° ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìˆ˜ì§‘í•  ê¸°ì‚¬ì˜ ìµœëŒ€ ê°œìˆ˜
MAX_ARTICLES_PER_CATEGORY = 100

# ìˆ˜ì§‘í•œ íŒŒì¼ì„ ì €ì¥í•  ê¸°ë³¸ í´ë” ê²½ë¡œ
save_path = "C:/Users/admin/Desktop/news"

# --- ì¤€ë¹„ ë‹¨ê³„ ---

# í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ 30ì¼ ì „ì˜ ë‚ ì§œë¥¼ ê³„ì‚° (ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •)
one_month_ago = datetime.now() - timedelta(days=30)

# ì €ì¥í•  í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
os.makedirs(save_path, exist_ok=True)
print(f"'{save_path}' í´ë”ì— ë‰´ìŠ¤ë¥¼ ì €ì¥í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"ê¸°ì¤€ ë‚ ì§œ: {one_month_ago.strftime('%Y-%m-%d')} ì´í›„ì˜ ê¸°ì‚¬ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
print(f"ëŒ€ìƒ ì–¸ë¡ ì‚¬: {', '.join(target_sources)}")
print(f"ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜: {MAX_ARTICLES_PER_CATEGORY}ê°œ")
print("-" * 60)

# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---

# categories ë”•ì…”ë„ˆë¦¬ì—ì„œ ëŒ€ë¶„ë¥˜ì™€ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì”© ê°€ì ¸ì™€ ë°˜ë³µ
for main_category, sub_categories in categories.items():
    
    # ëŒ€ë¶„ë¥˜ ì´ë¦„ìœ¼ë¡œ í´ë” ê²½ë¡œë¥¼ ìƒì„±
    main_category_path = os.path.join(save_path, main_category)
    os.makedirs(main_category_path, exist_ok=True)
    print(f"\nğŸ“ '{main_category}' í´ë”ì—ì„œ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    # í•´ë‹¹ ëŒ€ë¶„ë¥˜ì— ì†í•œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë“¤ì„ í•˜ë‚˜ì”© ë°˜ë³µ
    for sub_category in sub_categories:
        print(f"  -> '{sub_category}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        
        # URLì— í•œê¸€ í‚¤ì›Œë“œë¥¼ ë„£ê¸° ìœ„í•´ ì¸ì½”ë”©
        encoded_keyword = quote(sub_category)
        news_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR"
        
        # feedparserë¥¼ ì´ìš©í•´ RSS í”¼ë“œ ì •ë³´ë¥¼ íŒŒì‹±
        feed = feedparser.parse(news_url)
        
        # íŒŒì¼ ì´ë¦„ì— í¬í•¨ë  ìˆ˜ ì—†ëŠ” ë¬¸ìë¥¼ '_'ë¡œ ë³€ê²½
        file_name = f"{sub_category.replace('/', '_')}_news.txt"
        full_path = os.path.join(main_category_path, file_name)
        
        saved_in_category = 0
        
        try:
            # íŒŒì¼ì„ ì“°ê¸° ëª¨ë“œ('w')ë¡œ ì—´ê³ , í•œê¸€ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¸ì½”ë”© ì„¤ì •
            with open(full_path, 'w', encoding='utf-8') as f:
                # íŒŒì‹±ëœ í”¼ë“œì—ì„œ ê° ê¸°ì‚¬(entry) ì •ë³´ë¥¼ í•˜ë‚˜ì”© ë°˜ë³µ
                for entry in feed.entries:
                    # í˜„ì¬ ì¹´í…Œê³ ë¦¬ì—ì„œ ì €ì¥ëœ ê¸°ì‚¬ ìˆ˜ê°€ ìµœëŒ€ì¹˜ë¥¼ ë„˜ìœ¼ë©´ ì¤‘ë‹¨
                    if saved_in_category >= MAX_ARTICLES_PER_CATEGORY:
                        break

                    # ê¸°ì‚¬ì˜ ì–¸ë¡ ì‚¬ê°€ target_sources ëª©ë¡ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    if entry.source.title in target_sources:
                        published_time = entry.get('published_parsed')
                        if not published_time:
                            continue

                        # ê¸°ì‚¬ ë°œí–‰ ì‹œê°„ì„ íŒŒì´ì¬ datetime ê°ì²´ë¡œ ë³€í™˜
                        article_date = datetime.fromtimestamp(time.mktime(published_time))
                        
                        # ê¸°ì‚¬ ë°œí–‰ì¼ì´ ì„¤ì •ëœ ê¸°ê°„(ìµœê·¼ í•œ ë‹¬) ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                        if article_date >= one_month_ago:
                            # ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ íŒŒì¼ì— ì •ë³´ ì €ì¥
                            f.write(f"ì œëª©: {entry.title}\n")
                            f.write(f"ì–¸ë¡ ì‚¬: {entry.source.title}\n")
                            f.write(f"ë§í¬: {entry.link}\n")
                            f.write(f"ë°œí–‰ ì‹œê°„: {article_date.strftime('%Y-%m-%d %H:%M:%S')}\n")
                            f.write("-" * 50 + "\n\n")
                            saved_in_category += 1
            
            print(f"    âœ… '{file_name}' íŒŒì¼ì— {saved_in_category}ê°œì˜ ê¸°ì‚¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€ ì¶œë ¥
            print(f"    ğŸš¨ '{sub_category}' ë‰´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # êµ¬ê¸€ ì„œë²„ì— ë¶€ë‹´ì„ ì£¼ì§€ ì•Šê¸° ìœ„í•´ 1ì´ˆ ëŒ€ê¸°
        time.sleep(1)

print("\nğŸ‰ ëª¨ë“  ë‰´ìŠ¤ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")