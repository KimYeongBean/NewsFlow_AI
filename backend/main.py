import feedparser
import time
import os
from datetime import datetime, timedelta
from urllib.parse import quote
from openai import AzureOpenAI
import re

# ================================
# 1. ì „ì²´ ë‰´ìŠ¤/ì¹´í…Œê³ ë¦¬ ëª©ë¡
# ================================
all_sources = [
    'MBCë‰´ìŠ¤', 'ì—°í•©ë‰´ìŠ¤', 'ì¡°ì„ ì¼ë³´', 'ë‰´ìŠ¤1', 'JTBC ë‰´ìŠ¤',
    'ì¤‘ì•™ì¼ë³´', 'SBS ë‰´ìŠ¤', 'YTN', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸',
    'ì˜¤ë§ˆì´ë‰´ìŠ¤', 'í•œêµ­ê²½ì œ', 'ë§¤ì¼ê²½ì œ', 'í”„ë ˆì‹œì•ˆ', 'ë¨¸ë‹ˆíˆ¬ë°ì´'
]

categories = {
    'ì •ì¹˜': ['ëŒ€í†µë ¹ì‹¤', 'êµ­íšŒ', 'ì •ë‹¹', 'í–‰ì •', 'ì™¸êµ', 'êµ­ë°©/ë¶í•œ'],
    'ê²½ì œ': ['ê¸ˆìœµ/ì¦ê¶Œ', 'ì‚°ì—…/ì¬ê³„', 'ì¤‘ê¸°/ë²¤ì²˜', 'ë¶€ë™ì‚°', 'ê¸€ë¡œë²Œ', 'ìƒí™œ'],
    'ì‚¬íšŒ': ['ì‚¬ê±´ì‚¬ê³ ', 'êµìœ¡', 'ë…¸ë™', 'ì–¸ë¡ ', 'í™˜ê²½', 'ì¸ê¶Œ/ë³µì§€', 'ì‹í’ˆ/ì˜ë£Œ', 'ì§€ì—­', 'ì¸ë¬¼'],
    'IT_ê³¼í•™': ['ëª¨ë°”ì¼', 'ì¸í„°ë„·/SNS', 'í†µì‹ /ë‰´ë¯¸ë””ì–´', 'IT', 'ë³´ì•ˆ/í•´í‚¹', 'ì»´í“¨í„°', 'ê²Œì„/ë¦¬ë·°', 'ê³¼í•™'],
    'ìƒí™œ_ë¬¸í™”': ['ê±´ê°•', 'ìë™ì°¨', 'ì—¬í–‰/ë ˆì €', 'ìŒì‹/ë§›ì§‘', 'íŒ¨ì…˜/ë·°í‹°', 'ê³µì—°/ì „ì‹œ', 'ì±…', 'ì¢…êµ', 'ë‚ ì”¨', 'ìƒí™œ'],
    'ì„¸ê³„': ['ì•„ì‹œì•„/í˜¸ì£¼', 'ë¯¸êµ­/ì¤‘ë‚¨ë¯¸', 'ìœ ëŸ½', 'ì¤‘ë™/ì•„í”„ë¦¬ì¹´', 'ì„¸ê³„']
}

MAX_ARTICLES_PER_CATEGORY = 100
save_path = './output'

one_month_ago = datetime.now() - timedelta(days=30)
os.makedirs(save_path, exist_ok=True)

# ================================
# 2. Azure OpenAI ì´ˆê¸°í™”
# ================================
endpoint = "https://newscheck2.openai.azure.com/"
deployment = "gpt-5-nano"
api_key = "Dsf5DmuTn1cS7lXaSxSTnO30kTZCqr2xKqIjLwvdovEGnQsz3NjlJQQJ99BHACHYHv6XJ3w3AAABACOGJk53"

client = AzureOpenAI(
    azure_endpoint=endpoint,
    api_key=api_key,
    api_version="2025-01-01-preview",
)

# ================================
# 3. ì‚¬ìš©ì ì„¤ì • í•¨ìˆ˜
# ================================
def get_user_preferences():
    """ì‚¬ìš©ìë¡œë¶€í„° ì–¸ë¡ ì‚¬(5ê°œ)ì™€ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬(ë¬´ì œí•œ)ë¥¼ ì…ë ¥ë°›ëŠ” í•¨ìˆ˜"""
    print("ğŸ“° ë¶„ì„ì„ ì›í•˜ëŠ” ì–¸ë¡ ì‚¬ 5ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”. (ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„)")
    for i, source in enumerate(all_sources):
        print(f"{i+1}. {source}", end='  ')
    print("\n")
    
    selected_sources = []
    while len(selected_sources) != 5:
        try:
            user_input = input(">> ì„ íƒ (ë²ˆí˜¸ ë˜ëŠ” ì´ë¦„ 5ê°œ ì…ë ¥): ")
            inputs = [item.strip() for item in user_input.split(',')]
            
            if len(inputs) != 5:
                print("ğŸš¨ ë°˜ë“œì‹œ 5ê°œì˜ ì–¸ë¡ ì‚¬ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue

            temp_sources = []
            valid_input = True
            for item in inputs:
                if item.isdigit() and 1 <= int(item) <= len(all_sources):
                    temp_sources.append(all_sources[int(item) - 1])
                elif item in all_sources:
                    temp_sources.append(item)
                else:
                    print(f"ğŸš¨ '{item}'ì€(ëŠ”) ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ëª©ë¡ì— ìˆëŠ” ë²ˆí˜¸ë‚˜ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    valid_input = False
                    break
            
            if valid_input:
                unique_sources = sorted(list(set(temp_sources)))
                if len(unique_sources) == 5:
                    selected_sources = unique_sources
                else:
                    print("ğŸš¨ ì¤‘ë³µëœ ì„ íƒì´ ìˆê±°ë‚˜, 5ê°œê°€ ì•„ë‹™ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ğŸš¨ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    print(f"\nâœ… ì„ íƒëœ ì–¸ë¡ ì‚¬: {', '.join(selected_sources)}\n")

    print("ğŸ“š ìˆ˜ì§‘ì„ ì›í•˜ëŠ” ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”. (ê°¯ìˆ˜ ì œí•œ ì—†ìŒ, ì—¬ëŸ¬ ê°œ ì„ íƒ ì‹œ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„)")
    category_keys = list(categories.keys())
    for i, cat in enumerate(category_keys):
        print(f"{i+1}. {cat}", end='  ')
    print("\n")

    selected_categories = []
    while not selected_categories:
        try:
            user_input = input(">> ì„ íƒ (ë²ˆí˜¸ ë˜ëŠ” ì´ë¦„ ì…ë ¥): ")
            inputs = [item.strip() for item in user_input.split(',')]
            for item in inputs:
                if item.isdigit() and 1 <= int(item) <= len(category_keys):
                    selected_categories.append(category_keys[int(item) - 1])
                elif item in category_keys:
                    selected_categories.append(item)
            if not selected_categories:
                print("ğŸš¨ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ëª©ë¡ì— ìˆëŠ” ë²ˆí˜¸ë‚˜ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ğŸš¨ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    selected_categories = sorted(list(set(selected_categories)))
    print(f"\nâœ… ì„ íƒëœ ì¹´í…Œê³ ë¦¬: {', '.join(selected_categories)}\n")
    
    return selected_sources, selected_categories

# ================================
# 4. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
# ================================
def fetch_news(sub_category, main_category):
    encoded_keyword = quote(sub_category)
    news_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
    feed = feedparser.parse(news_url)

    articles = []
    saved_count = 0

    for entry in feed.entries:
        if saved_count >= MAX_ARTICLES_PER_CATEGORY:
            break

        source_name = getattr(entry, 'source', None)
        if source_name and source_name.title in all_sources:
            published_time = entry.get('published_parsed')
            if not published_time:
                continue
            
            article_date = datetime.fromtimestamp(time.mktime(published_time))
            if article_date < one_month_ago:
                continue

            content = re.sub('<[^<]+?>', '', entry.summary if hasattr(entry, 'summary') else entry.title)

            articles.append({
                'title': entry.title,
                'link': entry.link,
                'source': source_name.title,
                'date': article_date.strftime('%Y-%m-%d %H:%M:%S'),
                'content': content
            })
            saved_count += 1
    return articles

# ================================
# 5. GPT í‰ê°€ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ================================
def gpt_evaluate(article, selected_sources):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ê³  ì‹ ë¢°ë„ë¥¼ í‰ê°€í•˜ëŠ” í•¨ìˆ˜ (í”„ë¡¬í”„íŠ¸ ê°œì„ )"""
    # í”„ë¡¬í”„íŠ¸ë¥¼ ë” ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ëª¨ë¸ì´ ì§€ì‹œë¥¼ ë” ì˜ ë”°ë¥´ë„ë¡ í•¨
    prompt_text = f"""
ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤. ì•„ë˜ ìš”ì²­ì‚¬í•­ì— ë”°ë¼ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

[ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬]
- ì œëª©: {article['title']}
- ë‚´ìš©: {article['content']}

[ìš”ì²­ ì‚¬í•­]
1. [ìš”ì•½]: ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
2. [ì‹ ë¢°ë„]: ê¸°ì‚¬ì˜ ì‹ ë¢°ë„ë¥¼ 'ë†’ìŒ', 'ë³´í†µ', 'ë‚®ìŒ' ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. (í˜•ì‹: [í‰ê°€ ë“±ê¸‰] - [í‰ê°€ ì´ìœ ])

[ì‹ ë¢°ë„ í‰ê°€ ê¸°ì¤€]
- ë†’ìŒ: ì‚¬ì‹¤ ê´€ê³„ê°€ ëª…í™•í•˜ê³ , ì—¬ëŸ¬ ì¶œì²˜ì—ì„œ êµì°¨ í™•ì¸ì´ ê°€ëŠ¥í•˜ë©°, ê°ê´€ì ì¸ ë…¼ì¡°ë¥¼ ìœ ì§€í•˜ëŠ” ê²½ìš°.
- ë³´í†µ: ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì§€ë§Œ íŠ¹ì • ê´€ì ì´ ë‘ë“œëŸ¬ì§€ê±°ë‚˜, ì¼ë¶€ ì£¼ì¥ì— ëŒ€í•œ ê·¼ê±°ê°€ ë¶€ì¡±í•œ ê²½ìš°.
- ë‚®ìŒ: ê°ì •ì ì´ê±°ë‚˜ ìê·¹ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ê³ , í™•ì¸ë˜ì§€ ì•Šì€ ì‚¬ì‹¤ì„ ì „ë‹¬í•˜ê±°ë‚˜, ëª…ë°±í•œ í¸í–¥ì„±ì„ ë³´ì´ëŠ” ê²½ìš°.
"""
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ [ìš”ì•½]ê³¼ [ì‹ ë¢°ë„] ë‘ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„í•˜ê³ , ì§€ì •ëœ í˜•ì‹ì— ë§ì¶° ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” AIì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt_text}
    ]

    try:
        completion = client.chat.completions.create(
            model=deployment,
            messages=messages,
            max_tokens=1500,
            temperature=0.3, # ë” ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ë‚®ì¶¤
        )
        result_text = completion.choices[0].message.content.strip()
        return result_text
    except Exception as e:
        return f"GPT í‰ê°€ ì˜¤ë¥˜: {e}"

# ================================
# 6. HTML ì €ì¥ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ================================
def save_news_to_html(main_category, sub_category, articles):
    """ìˆ˜ì§‘í•˜ê³  í‰ê°€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ HTML íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    main_path = os.path.join(save_path, main_category)
    os.makedirs(main_path, exist_ok=True)
    
    safe_sub_category = sub_category.replace('/', '_').replace('\\', '_')
    file_name = f"{safe_sub_category}_news.html"
    full_path = os.path.join(main_path, file_name)

    with open(full_path, 'w', encoding='utf-8') as f:
        f.write("<!DOCTYPE html><html lang='ko'><head><meta charset='utf-8'>")
        f.write(f"<title>{main_category} - {sub_category} ë‰´ìŠ¤</title>")
        f.write("<style>")
        f.write("""
            body { font-family: 'Malgun Gothic', sans-serif; line-height: 1.6; margin: 20px; background-color: #f4f4f9; color: #333; }
            h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
            .article { background-color: #fff; border: 1px solid #ddd; border-radius: 8px; padding: 20px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .article h3 a { color: #3498db; text-decoration: none; }
            .article h3 a:hover { text-decoration: underline; }
            .meta { font-size: 0.9em; color: #7f8c8d; margin-bottom: 15px; }
            .evaluation { background-color: #ecf0f1; border-left: 4px solid #3498db; padding: 15px; margin-top: 15px; border-radius: 4px; }
            .reliability { font-weight: bold; padding: 3px 8px; border-radius: 12px; color: white; font-size: 0.9em; }
            .high { background-color: #2ecc71; }
            .medium { background-color: #f39c12; }
            .low { background-color: #e74c3c; }
        """)
        f.write("</style></head><body>\n")
        f.write(f"<h1>{main_category} - {sub_category}</h1>\n")

        if not articles:
            f.write("<p>í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</p>")

        for article in articles:
            evaluation_text = article.get('evaluation', '')
            
            # ë” ì•ˆì •ì ì¸ íŒŒì‹±ì„ ìœ„í•´ ì •ê·œ í‘œí˜„ì‹ ìˆ˜ì •
            summary_match = re.search(r'\[ìš”ì•½\](.*?)(?=\[ì‹ ë¢°ë„\]|\Z)', evaluation_text, re.DOTALL)
            reliability_match = re.search(r'\[ì‹ ë¢°ë„\]\s*(ë†’ìŒ|ë³´í†µ|ë‚®ìŒ)\s*-\s*(.*)', evaluation_text, re.DOTALL)

            summary = summary_match.group(1).strip().replace('\n', '<br>') if summary_match else "ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            reliability_grade = "í‰ê°€ ì‹¤íŒ¨"
            reliability_reason = ""
            reliability_class = ""

            if reliability_match:
                reliability_grade = reliability_match.group(1).strip()
                reliability_reason = reliability_match.group(2).strip()
                if reliability_grade == "ë†’ìŒ": reliability_class = "high"
                elif reliability_grade == "ë³´í†µ": reliability_class = "medium"
                elif reliability_grade == "ë‚®ìŒ": reliability_class = "low"
            else:
                # GPT ì‘ë‹µ ì „ì²´ë¥¼ ì´ìœ ë¡œ í‘œì‹œí•˜ì—¬ ë””ë²„ê¹…ì— ìš©ì´í•˜ê²Œ í•¨
                reliability_reason = f"ì‹ ë¢°ë„ ì •ë³´ë¥¼ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸ ì‘ë‹µ: {evaluation_text})"

            f.write("<div class='article'>\n")
            f.write(f"<h3><a href='{article['link']}' target='_blank' rel='noopener noreferrer'>{article['title']}</a></h3>\n")
            f.write(f"<p class='meta'><b>ì–¸ë¡ ì‚¬:</b> {article['source']} | <b>ë°œí–‰ ì‹œê°„:</b> {article['date']}</p>\n")
            f.write("<div class='evaluation'>\n")
            f.write(f"<p><b>ğŸ¤– AI ìš”ì•½:</b><br>{summary}</p>\n")
            f.write(f"<p><b>â­ ì‹ ë¢°ë„ í‰ê°€:</b> <span class='reliability {reliability_class}'>{reliability_grade}</span> - {reliability_reason}</p>\n")
            f.write("</div>\n</div>\n")

        f.write("</body></html>")

# ================================
# 7. ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ================================
if __name__ == "__main__":
    user_selected_sources, user_follow_categories = get_user_preferences()

    print("\nğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    for main_category in user_follow_categories:
        sub_categories = categories.get(main_category, [])
        for sub_category in sub_categories:
            print(f"[{main_category}] '{sub_category}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            articles = fetch_news(sub_category, main_category)

            if not articles:
                print(f"  -> ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            print(f"  -> {len(articles)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ. GPT í‰ê°€ ì‹œì‘...")
            for i, article in enumerate(articles):
                print(f"    - ê¸°ì‚¬ {i+1}/{len(articles)} í‰ê°€ ì¤‘...")
                article['evaluation'] = gpt_evaluate(article, user_selected_sources)
                time.sleep(1)

            save_news_to_html(main_category, sub_category, articles)
            print(f"  -> '{sub_category}' ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ.\n")

    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! 'output' í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
