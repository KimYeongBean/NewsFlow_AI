# ================================
# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
# ================================
# FastAPI í”„ë ˆì„ì›Œí¬ì™€ API ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ HTTPExceptionì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from fastapi import FastAPI, HTTPException
# ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ë¥¼ ìœ„í•œ BaseModelê³¼ í•„ë“œ ì„¤ì •ì„ ìœ„í•œ Fieldë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from pydantic import BaseModel, Field
# íƒ€ì… íŒíŒ…(Type Hinting)ì„ ìœ„í•´ Listì™€ Dictë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì½”ë“œì˜ ê°€ë…ì„±ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.
from typing import List, Dict
# ì›¹ì‚¬ì´íŠ¸ì˜ RSS í”¼ë“œë¥¼ íŒŒì‹±(ë¶„ì„)í•˜ê¸° ìœ„í•œ feedparser ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
import feedparser
# ë‚ ì§œì™€ ì‹œê°„ì„ ë‹¤ë£¨ê¸° ìœ„í•œ datetimeê³¼ timedeltaë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from datetime import datetime, timedelta
# URLì— í•œê¸€ ë“± ë¹„ASCII ë¬¸ìë¥¼ ì•ˆì „í•˜ê²Œ í¬í•¨ì‹œí‚¤ê¸° ìœ„í•œ quote í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from urllib.parse import quote
# Azure OpenAI APIë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ AsyncAzureOpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from openai import AsyncAzureOpenAI
# ì •ê·œ í‘œí˜„ì‹(Regular Expression)ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ re ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
import re
# ë¹„ë™ê¸° ì‘ì—…ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ asyncio ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
import asyncio
# í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë“± ì‹œê°„ ê´€ë ¨ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ time ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
import time

# ================================
# 1. FastAPI ì•± ì´ˆê¸°í™” ë° ê¸°ë³¸ ì„¤ì •
# ================================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê°ì²´ë¥¼ í†µí•´ API ì„œë²„ê°€ ë™ì‘í•©ë‹ˆë‹¤.
app = FastAPI(
    # API ë¬¸ì„œì— í‘œì‹œë  ì œëª©ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    title="ë‰´ìŠ¤ ë¶„ì„ API (News Analyzer API)",
    # API ë¬¸ì„œì— í‘œì‹œë  ìƒì„¸ ì„¤ëª…ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    description="ì„ íƒí•œ ì–¸ë¡ ì‚¬ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  AIë¡œ ìš”ì•½ ë° ì‹ ë¢°ë„ë¥¼ í‰ê°€í•˜ëŠ” APIì…ë‹ˆë‹¤.",
    # APIì˜ ë²„ì „ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    version="2.0.0"
)

# ë¶„ì„ ëŒ€ìƒ ë° ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì „ì²´ ì–¸ë¡ ì‚¬ ëª©ë¡ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
all_sources = [
    'MBCë‰´ìŠ¤', 'ì—°í•©ë‰´ìŠ¤', 'ì¡°ì„ ì¼ë³´', 'ë‰´ìŠ¤1', 'JTBC ë‰´ìŠ¤',
    'ì¤‘ì•™ì¼ë³´', 'SBS ë‰´ìŠ¤', 'YTN', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸',
    'ì˜¤ë§ˆì´ë‰´ìŠ¤', 'í•œêµ­ê²½ì œ', 'ë§¤ì¼ê²½ì œ', 'í”„ë ˆì‹œì•ˆ', 'ë¨¸ë‹ˆíˆ¬ë°ì´'
]

# ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ëŒ€ë¶„ë¥˜(Key)ì™€ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸(Value)ë¡œ êµ¬ì„±ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
categories = {
    'ì •ì¹˜': ['ëŒ€í†µë ¹ì‹¤', 'êµ­íšŒ', 'ì •ë‹¹', 'í–‰ì •', 'ì™¸êµ', 'êµ­ë°©/ë¶í•œ'],
    'ê²½ì œ': ['ê¸ˆìœµ/ì¦ê¶Œ', 'ì‚°ì—…/ì¬ê³„', 'ì¤‘ê¸°/ë²¤ì²˜', 'ë¶€ë™ì‚°', 'ê¸€ë¡œë²Œ', 'ìƒí™œ'],
    'ì‚¬íšŒ': ['ì‚¬ê±´ì‚¬ê³ ', 'êµìœ¡', 'ë…¸ë™', 'ì–¸ë¡ ', 'í™˜ê²½', 'ì¸ê¶Œ/ë³µì§€', 'ì‹í’ˆ/ì˜ë£Œ', 'ì§€ì—­', 'ì¸ë¬¼'],
    'IT_ê³¼í•™': ['ëª¨ë°”ì¼', 'ì¸í„°ë„·/SNS', 'í†µì‹ /ë‰´ë¯¸ë””ì–´', 'IT', 'ë³´ì•ˆ/í•´í‚¹', 'ì»´í“¨í„°', 'ê²Œì„/ë¦¬ë·°', 'ê³¼í•™'],
    'ìƒí™œ_ë¬¸í™”': ['ê±´ê°•', 'ìë™ì°¨', 'ì—¬í–‰/ë ˆì €', 'ìŒì‹/ë§›ì§‘', 'íŒ¨ì…˜/ë·°í‹°', 'ê³µì—°/ì „ì‹œ', 'ì±…', 'ì¢…êµ', 'ë‚ ì”¨', 'ìƒí™œ'],
    'ì„¸ê³„': ['ì•„ì‹œì•„/í˜¸ì£¼', 'ë¯¸êµ­/ì¤‘ë‚¨ë¯¸', 'ìœ ëŸ½', 'ì¤‘ë™/ì•„í”„ë¦¬ì¹´', 'ì„¸ê³„']
}

# ğŸ’¡ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ê¸° í¸í•˜ë„ë¡ ëª¨ë“  ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜(List Comprehension)ì„ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê²Œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
all_sub_categories = [sub for main in categories.values() for sub in main]

# í•˜ë‚˜ì˜ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë‹¹ ìˆ˜ì§‘í•  ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ë¥¼ 10ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤.
MAX_ARTICLES_PER_CATEGORY = 10
# í˜„ì¬ ì‹œê°„ìœ¼ë¡œë¶€í„° 30ì¼ ì´ì „ì˜ ë‚ ì§œë¥¼ ê³„ì‚°í•˜ì—¬, ì´ë³´ë‹¤ ì˜¤ë˜ëœ ê¸°ì‚¬ëŠ” ìˆ˜ì§‘ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
one_month_ago = datetime.now() - timedelta(days=30)

# ================================
# 2. Azure OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ================================
# Azure OpenAI ì„œë¹„ìŠ¤ì— ì—°ê²°í•˜ê¸° ìœ„í•œ ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
async_client = AsyncAzureOpenAI(
    # Azureì— ë°°í¬ëœ OpenAI ì„œë¹„ìŠ¤ì˜ ê³ ìœ  ì£¼ì†Œ(ì—”ë“œí¬ì¸íŠ¸)ì…ë‹ˆë‹¤.
    azure_endpoint="https://newscheck2.openai.azure.com/",
    # ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ API ì¸ì¦ í‚¤ì…ë‹ˆë‹¤.
    api_key="Dsf5DmuTn1cS7lXaSxSTnO30kTZCqr2xKqIjLwvdovEGnQsz3NjlJQQJ99BHACHYHv6XJ3w3AAABACOGJk53",
    # ì‚¬ìš©í•  APIì˜ ë²„ì „ì…ë‹ˆë‹¤.
    api_version="2025-01-01-preview",
)

# ================================
# 3. API ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic) - ìˆ˜ì •ë¨
# ================================
# APIê°€ ìš”ì²­(Request)ì„ ë°›ì„ ë•Œ ë°ì´í„°ì˜ í˜•ì‹ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.
class AnalysisRequest(BaseModel):
    # 'selected_sources'ëŠ” ë¬¸ìì—´(str)ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸(List)ì—¬ì•¼ í•©ë‹ˆë‹¤.
    # Fieldì˜ '...'ëŠ” ì´ í•„ë“œê°€ í•„ìˆ˜ê°’ì„ì„ ì˜ë¯¸í•˜ë©°, min/max_lengthë¡œ ê°œìˆ˜ë¥¼ 5ê°œë¡œ ê°•ì œí•©ë‹ˆë‹¤.
    selected_sources: List[str] = Field(..., description="ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì„ ì–¸ë¡ ì‚¬ 5ê°œì˜ ëª©ë¡", min_length=5, max_length=5)
    # ğŸ’¡ ì´ì œ ìƒìœ„ ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹Œ, ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¥¼ ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŠµë‹ˆë‹¤.
    # 'selected_sub_categories'ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì´ë©°, ìµœì†Œ 1ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    selected_sub_categories: List[str] = Field(..., description="ìˆ˜ì§‘ì„ ì›í•˜ëŠ” ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ëª©ë¡ (ìµœì†Œ 1ê°œ ì´ìƒ)", min_length=1)

# APIê°€ ì‘ë‹µ(Response)ì„ ë³´ë‚¼ ë•Œ ë°ì´í„°ì˜ í˜•ì‹ì„ ì •ì˜í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
class EvaluatedArticle(BaseModel):
    # ê° í•„ë“œê°€ ì–´ë–¤ íƒ€ì…ì´ì–´ì•¼ í•˜ëŠ”ì§€ ì§€ì •í•©ë‹ˆë‹¤. (ì˜ˆ: titleì€ ë°˜ë“œì‹œ ë¬¸ìì—´ì´ì–´ì•¼ í•¨)
    title: str
    link: str
    source: str
    date: str
    summary: str
    reliability_grade: str
    reliability_reason: str

# ================================
# 4. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ (gpt_evaluate_async ê°•í™”)
# ================================
# ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
def fetch_news(sub_category: str) -> List[Dict]:
    # URLì— í•œê¸€ í‚¤ì›Œë“œë¥¼ í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ UTF-8 ì¸ì½”ë”©ì„ í•©ë‹ˆë‹¤.
    encoded_keyword = quote(sub_category)
    # êµ¬ê¸€ ë‰´ìŠ¤ RSS ê²€ìƒ‰ì„ ìœ„í•œ URLì„ ìƒì„±í•©ë‹ˆë‹¤.
    news_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
    # feedparserë¡œ í•´ë‹¹ URLì˜ RSS ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    feed = feedparser.parse(news_url)
    # ìˆ˜ì§‘ëœ ê¸°ì‚¬ë¥¼ ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    articles = []
    # RSS í”¼ë“œì— í¬í•¨ëœ ëª¨ë“  ê¸°ì‚¬ í•­ëª©(entry)ì„ ìˆœíšŒí•©ë‹ˆë‹¤.
    for entry in feed.entries:
        # ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ì— ë„ë‹¬í•˜ë©´ ë°˜ë³µì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
        if len(articles) >= MAX_ARTICLES_PER_CATEGORY: break
        # ê¸°ì‚¬ì˜ ì¶œì²˜(ì–¸ë¡ ì‚¬) ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì—†ìœ¼ë©´ Noneì´ ë©ë‹ˆë‹¤.
        source_name = getattr(entry, 'source', None)
        # ì–¸ë¡ ì‚¬ ì •ë³´ê°€ ìˆê³ , ìš°ë¦¬ê°€ ì •ì˜í•œ ì–¸ë¡ ì‚¬ ëª©ë¡ì— í¬í•¨ëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        if source_name and source_name.title in all_sources:
            # ê¸°ì‚¬ì˜ ë°œí–‰ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            published_time = entry.get('published_parsed')
            # ë°œí–‰ ì‹œê°„ì´ ì—†ìœ¼ë©´ ì´ ê¸°ì‚¬ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.
            if not published_time: continue
            # ë°œí–‰ ì‹œê°„ì„ íŒŒì´ì¬ datetime ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            article_date = datetime.fromtimestamp(time.mktime(published_time))
            # ê¸°ì‚¬ê°€ 30ì¼ë³´ë‹¤ ì˜¤ë˜ë˜ì—ˆìœ¼ë©´ ê±´ë„ˆëœë‹ˆë‹¤.
            if article_date < one_month_ago: continue
            # ê¸°ì‚¬ ë³¸ë¬¸/ìš”ì•½ì—ì„œ HTML íƒœê·¸ë¥¼ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤.
            content = re.sub('<[^<]+?>', '', entry.summary if hasattr(entry, 'summary') else entry.title)
            # í•„ìš”í•œ ì •ë³´ë§Œ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•˜ì—¬ articles ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            articles.append({
                'title': entry.title, 'link': entry.link, 'source': source_name.title,
                'date': article_date.strftime('%Y-%m-%d %H:%M:%S'), 'content': content
            })
    # ìµœì¢…ì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return articles

# ğŸ’¡ GPT í‰ê°€ í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°(async) í•¨ìˆ˜ë¡œ ì •ì˜í•˜ì—¬ ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
async def gpt_evaluate_async(article: Dict) -> Dict:
    # GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸(ì§€ì‹œë¬¸)ë¥¼ f-string í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    prompt_text = f"""
[ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬]
- ì œëª©: {article['title']}
- ë‚´ìš©: {article['content']}

[ìš”ì²­ ì‚¬í•­]
1. [ìš”ì•½]: ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
2. [ì‹ ë¢°ë„]: ê¸°ì‚¬ì˜ ì‹ ë¢°ë„ë¥¼ 'ë†’ìŒ', 'ë³´í†µ', 'ë‚®ìŒ' ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. (í˜•ì‹: [í‰ê°€ ë“±ê¸‰] - [í‰ê°€ ì´ìœ ])
"""
    # OpenAI APIê°€ ìš”êµ¬í•˜ëŠ” ëŒ€í™” í˜•ì‹(messages)ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ [ìš”ì•½]ê³¼ [ì‹ ë¢°ë„] ë‘ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„í•˜ê³ , ì§€ì •ëœ í˜•ì‹ì— ë§ì¶° ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” AIì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt_text}
    ]
    # API í˜¸ì¶œ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ try-except ë¸”ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    try:
        # 'await' í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ì ìœ¼ë¡œ OpenAI APIë¥¼ í˜¸ì¶œí•˜ê³  ì‘ë‹µì´ ì˜¬ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        completion = await async_client.chat.completions.create(
            model="gpt-5-nano", messages=messages, max_completion_tokens=1500, temperature=0.3
        )
        # API ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³  ì•ë’¤ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.
        response_text = completion.choices[0].message.content.strip()
        
        # ğŸ’¡ íŒŒì‹± ë¡œì§ ê°•í™”: ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ GPT ì‘ë‹µì—ì„œ '[ìš”ì•½]' ë¶€ë¶„ì„ ì°¾ìŠµë‹ˆë‹¤.
        summary_match = re.search(r'\[ìš”ì•½\](.*?)(?=\[ì‹ ë¢°ë„\]|\Z)', response_text, re.DOTALL)
        # ìš”ì•½ ë¶€ë¶„ì„ ì°¾ì•˜ìœ¼ë©´ í•´ë‹¹ ë‚´ìš©ì„, ëª» ì°¾ì•˜ìœ¼ë©´ ì‹¤íŒ¨ ë©”ì‹œì§€ë¥¼ summary ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
        summary = summary_match.group(1).strip() if summary_match else "ìš”ì•½ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ GPT ì‘ë‹µì—ì„œ '[ì‹ ë¢°ë„]' ë¶€ë¶„ê³¼ ë“±ê¸‰, ì´ìœ ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        reliability_match = re.search(r'\[ì‹ ë¢°ë„\]\s*(ë†’ìŒ|ë³´í†µ|ë‚®ìŒ)\s*-\s*(.*)', response_text, re.DOTALL)
        # ì‹ ë¢°ë„ ë¶€ë¶„ì„ ì°¾ì•˜ìœ¼ë©´ ë“±ê¸‰ê³¼ ì´ìœ ë¥¼ ê°ê° ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
        if reliability_match:
            grade = reliability_match.group(1).strip()
            reason = reliability_match.group(2).strip()
        # ëª» ì°¾ì•˜ìœ¼ë©´ ì‹¤íŒ¨ ìƒíƒœì™€ ì›ë³¸ ì‘ë‹µì˜ ì¼ë¶€ë¥¼ ì €ì¥í•˜ì—¬ ë””ë²„ê¹…ì„ ë•ìŠµë‹ˆë‹¤.
        else:
            grade = "í‰ê°€ ì‹¤íŒ¨"
            reason = f"ì‹ ë¢°ë„ ì •ë³´ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. [ì›ë³¸ ì‘ë‹µ: {response_text[:100]}...]"
            
        # ìµœì¢… ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {"summary": summary, "reliability_grade": grade, "reliability_reason": reason}
    # API í˜¸ì¶œì´ë‚˜ ë‹¤ë¥¸ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ê²½ìš°
    except Exception as e:
        # ì˜¤ë¥˜ ë‚´ìš©ì„ í¬í•¨í•œ ì‹¤íŒ¨ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {"summary": "GPT API ì˜¤ë¥˜", "reliability_grade": "ì˜¤ë¥˜", "reliability_reason": f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

# ================================
# 5. API ì—”ë“œí¬ì¸íŠ¸(Endpoint) ì •ì˜ - ìˆ˜ì •ë¨
# ================================
# '/options' ê²½ë¡œë¡œ GET ìš”ì²­ì´ ì™”ì„ ë•Œ ì‹¤í–‰ë  í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
@app.get("/options", summary="ì„ íƒ ê°€ëŠ¥í•œ ì–¸ë¡ ì‚¬ ë° ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ")
def get_options():
    """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©ìì—ê²Œ ì„ íƒì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” APIì…ë‹ˆë‹¤."""
    # ğŸ’¡ ì´ì œ ì„¸ë¶„í™”ëœ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ì œê³µí•©ë‹ˆë‹¤.
    return {"all_sources": all_sources, "all_sub_categories": all_sub_categories}

# '/analyze' ê²½ë¡œë¡œ POST ìš”ì²­ì´ ì™”ì„ ë•Œ ì‹¤í–‰ë  ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
@app.post("/analyze", summary="ë‰´ìŠ¤ ë¶„ì„ ìš”ì²­", response_model=Dict[str, List[EvaluatedArticle]])
async def analyze_news(request: AnalysisRequest):
    """ì‚¬ìš©ìë¡œë¶€í„° ì–¸ë¡ ì‚¬ ë° ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ë°›ì•„ ë‰´ìŠ¤ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ê°€ ìš°ë¦¬ê°€ ì •ì˜í•œ ëª©ë¡ì— ìˆëŠ”ì§€ í•˜ë‚˜ì”© í™•ì¸í•©ë‹ˆë‹¤.
    for sub_cat in request.selected_sub_categories:
        # ë§Œì•½ ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ê°€ ìˆë‹¤ë©´, 400 ì˜¤ë¥˜ ì½”ë“œì™€ í•¨ê»˜ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        if sub_cat not in all_sub_categories:
            raise HTTPException(status_code=400, detail=f"'{sub_cat}'ì€(ëŠ”) ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤.")

    # ìµœì¢… ê²°ê³¼ë¥¼ ë‹´ì„ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    final_results = {}
    
    # ğŸ’¡ ì´ì œ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ì§ì ‘ ìˆœíšŒí•©ë‹ˆë‹¤.
    for sub_category in request.selected_sub_categories:
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        articles_to_evaluate = fetch_news(sub_category)
        # ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
        if not articles_to_evaluate: continue

        # ìˆ˜ì§‘ëœ ëª¨ë“  ê¸°ì‚¬ì— ëŒ€í•´ GPT í‰ê°€ ë¹„ë™ê¸° ì‘ì—…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤. (ì•„ì§ ì‹¤í–‰ ì „)
        evaluation_tasks = [gpt_evaluate_async(article) for article in articles_to_evaluate]
        # asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í‰ê°€ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³ , ëª¨ë“  ê²°ê³¼ê°€ ì˜¬ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        evaluations = await asyncio.gather(*evaluation_tasks)

        # ì›ë³¸ ê¸°ì‚¬ ì •ë³´(article)ì™€ GPT í‰ê°€ ê²°ê³¼(evaluation)ë¥¼ ì§ì§€ì–´ ìµœì¢… ì‘ë‹µ ëª¨ë¸ì— ë§ê²Œ ì •ë¦¬í•©ë‹ˆë‹¤.
        evaluated_articles = [
            EvaluatedArticle(
                title=article['title'], link=article['link'], source=article['source'],
                date=article['date'], summary=evaluation['summary'],
                reliability_grade=evaluation['reliability_grade'],
                reliability_reason=evaluation['reliability_reason']
            )
            for article, evaluation in zip(articles_to_evaluate, evaluations)
        ]
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ Keyë¡œ í•˜ì—¬ ë¶„ì„ëœ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        final_results[sub_category] = evaluated_articles

    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ì²˜ë¦¬í–ˆëŠ”ë°ë„ ê²°ê³¼ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´, 404 ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    if not final_results:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ë¶„ì„í•  ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ìµœì¢… ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    return final_results
