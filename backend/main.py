# ================================
# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
# ================================
# FastAPI ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict

# ê¸°ì¡´ ë‰´ìŠ¤ ë¶„ì„ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
import feedparser
from datetime import datetime, timedelta
from urllib.parse import quote
from openai import AsyncAzureOpenAI # ğŸ’¡ ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•´ AsyncAzureOpenAIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
import re
import asyncio # ğŸ’¡ ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë¹„ë™ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬

# ================================
# 1. FastAPI ì•± ì´ˆê¸°í™” ë° ê¸°ë³¸ ì„¤ì •
# ================================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê°ì²´ê°€ API ì„œë²„ì˜ ì¤‘ì‹¬ì´ ë©ë‹ˆë‹¤.
app = FastAPI(
    title="ë‰´ìŠ¤ ë¶„ì„ API (News Analyzer API)",
    description="ì„ íƒí•œ ì–¸ë¡ ì‚¬ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  AIë¡œ ìš”ì•½ ë° ì‹ ë¢°ë„ë¥¼ í‰ê°€í•˜ëŠ” APIì…ë‹ˆë‹¤.",
    version="1.0.0"
)

# ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì „ì²´ ì–¸ë¡ ì‚¬ ëª©ë¡ì…ë‹ˆë‹¤.
all_sources = [
    'MBCë‰´ìŠ¤', 'ì—°í•©ë‰´ìŠ¤', 'ì¡°ì„ ì¼ë³´', 'ë‰´ìŠ¤1', 'JTBC ë‰´ìŠ¤',
    'ì¤‘ì•™ì¼ë³´', 'SBS ë‰´ìŠ¤', 'YTN', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸',
    'ì˜¤ë§ˆì´ë‰´ìŠ¤', 'í•œêµ­ê²½ì œ', 'ë§¤ì¼ê²½ì œ', 'í”„ë ˆì‹œì•ˆ', 'ë¨¸ë‹ˆíˆ¬ë°ì´'
]

# ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì…ë‹ˆë‹¤.
categories = {
    'ì •ì¹˜': ['ëŒ€í†µë ¹ì‹¤', 'êµ­íšŒ', 'ì •ë‹¹', 'í–‰ì •', 'ì™¸êµ', 'êµ­ë°©/ë¶í•œ'],
    'ê²½ì œ': ['ê¸ˆìœµ/ì¦ê¶Œ', 'ì‚°ì—…/ì¬ê³„', 'ì¤‘ê¸°/ë²¤ì²˜', 'ë¶€ë™ì‚°', 'ê¸€ë¡œë²Œ', 'ìƒí™œ'],
    'ì‚¬íšŒ': ['ì‚¬ê±´ì‚¬ê³ ', 'êµìœ¡', 'ë…¸ë™', 'ì–¸ë¡ ', 'í™˜ê²½', 'ì¸ê¶Œ/ë³µì§€', 'ì‹í’ˆ/ì˜ë£Œ', 'ì§€ì—­', 'ì¸ë¬¼'],
    'IT_ê³¼í•™': ['ëª¨ë°”ì¼', 'ì¸í„°ë„·/SNS', 'í†µì‹ /ë‰´ë¯¸ë””ì–´', 'IT', 'ë³´ì•ˆ/í•´í‚¹', 'ì»´í“¨í„°', 'ê²Œì„/ë¦¬ë·°', 'ê³¼í•™'],
    'ìƒí™œ_ë¬¸í™”': ['ê±´ê°•', 'ìë™ì°¨', 'ì—¬í–‰/ë ˆì €', 'ìŒì‹/ë§›ì§‘', 'íŒ¨ì…˜/ë·°í‹°', 'ê³µì—°/ì „ì‹œ', 'ì±…', 'ì¢…êµ', 'ë‚ ì”¨', 'ìƒí™œ'],
    'ì„¸ê³„': ['ì•„ì‹œì•„/í˜¸ì£¼', 'ë¯¸êµ­/ì¤‘ë‚¨ë¯¸', 'ìœ ëŸ½', 'ì¤‘ë™/ì•„í”„ë¦¬ì¹´', 'ì„¸ê³„']
}

MAX_ARTICLES_PER_CATEGORY = 10 # ğŸ’¡ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ë¥¼ 10ê°œë¡œ ì¤„ì…ë‹ˆë‹¤. í•„ìš”ì‹œ ëŠ˜ë¦¬ì„¸ìš”.
one_month_ago = datetime.now() - timedelta(days=30)

# ================================
# 2. Azure OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ================================
async_client = AsyncAzureOpenAI(
    azure_endpoint="https://newscheck2.openai.azure.com/",
    api_key="Dsf5DmuTn1cS7lXaSxSTnO30kTZCqr2xKqIjLwvdovEGnQsz3NjlJQQJ99BHACHYHv6XJ3w3AAABACOGJk53",
    api_version="2025-01-01-preview",
)

# ================================
# 3. API ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic)
# ================================
# API ìš”ì²­ ì‹œ bodyì— í¬í•¨ë  ë°ì´í„°ì˜ í˜•ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.
class AnalysisRequest(BaseModel):
    selected_sources: List[str] = Field(..., description="ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì„ ì–¸ë¡ ì‚¬ 5ê°œì˜ ëª©ë¡", min_length=5, max_length=5)
    selected_categories: List[str] = Field(..., description="ìˆ˜ì§‘ì„ ì›í•˜ëŠ” ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡ (ìµœì†Œ 1ê°œ ì´ìƒ)", min_length=1)

# API ì‘ë‹µ ì‹œ ë°˜í™˜ë  ë°ì´í„°ì˜ í˜•ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.
class EvaluatedArticle(BaseModel):
    title: str
    link: str
    source: str
    date: str
    summary: str
    reliability_grade: str
    reliability_reason: str

# ================================
# 4. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš© ë° ìˆ˜ì •)
# ================================
# ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.
def fetch_news(sub_category: str) -> List[Dict]:
    encoded_keyword = quote(sub_category)
    news_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
    feed = feedparser.parse(news_url)
    articles = []
    for entry in feed.entries:
        if len(articles) >= MAX_ARTICLES_PER_CATEGORY: break
        source_name = getattr(entry, 'source', None)
        if source_name and source_name.title in all_sources:
            published_time = entry.get('published_parsed')
            if not published_time: continue
            article_date = datetime.fromtimestamp(time.mktime(published_time))
            if article_date < one_month_ago: continue
            content = re.sub('<[^<]+?>', '', entry.summary if hasattr(entry, 'summary') else entry.title)
            articles.append({
                'title': entry.title, 'link': entry.link, 'source': source_name.title,
                'date': article_date.strftime('%Y-%m-%d %H:%M:%S'), 'content': content
            })
    return articles

# ğŸ’¡ GPT í‰ê°€ í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°(async) í•¨ìˆ˜ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
async def gpt_evaluate_async(article: Dict) -> Dict:
    prompt_text = f"""
[ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬]
- ì œëª©: {article['title']}
- ë‚´ìš©: {article['content']}

[ìš”ì²­ ì‚¬í•­]
1. [ìš”ì•½]: ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
2. [ì‹ ë¢°ë„]: ê¸°ì‚¬ì˜ ì‹ ë¢°ë„ë¥¼ 'ë†’ìŒ', 'ë³´í†µ', 'ë‚®ìŒ' ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. (í˜•ì‹: [í‰ê°€ ë“±ê¸‰] - [í‰ê°€ ì´ìœ ])
"""
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ [ìš”ì•½]ê³¼ [ì‹ ë¢°ë„] ë‘ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„í•˜ê³ , ì§€ì •ëœ í˜•ì‹ì— ë§ì¶° ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” AIì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt_text}
    ]
    try:
        # ğŸ’¡ 'await'ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ì ìœ¼ë¡œ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        completion = await async_client.chat.completions.create(
            model="gpt-5-nano", messages=messages, max_completion_tokens=1500, temperature=0.3
        )
        response_text = completion.choices[0].message.content.strip()
        
        summary_match = re.search(r'\[ìš”ì•½\](.*?)(?=\[ì‹ ë¢°ë„\]|\Z)', response_text, re.DOTALL)
        reliability_match = re.search(r'\[ì‹ ë¢°ë„\]\s*(ë†’ìŒ|ë³´í†µ|ë‚®ìŒ)\s*-\s*(.*)', response_text, re.DOTALL)
        
        summary = summary_match.group(1).strip() if summary_match else "ìš”ì•½ ì‹¤íŒ¨"
        if reliability_match:
            grade = reliability_match.group(1).strip()
            reason = reliability_match.group(2).strip()
        else:
            grade = "í‰ê°€ ì‹¤íŒ¨"
            reason = "ì‹ ë¢°ë„ ì •ë³´ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
        return {"summary": summary, "reliability_grade": grade, "reliability_reason": reason}
    except Exception as e:
        return {"summary": "GPT ì˜¤ë¥˜", "reliability_grade": "ì˜¤ë¥˜", "reliability_reason": str(e)}

# ================================
# 5. API ì—”ë“œí¬ì¸íŠ¸(Endpoint) ì •ì˜
# ================================
# '/options' ì£¼ì†Œë¡œ GET ìš”ì²­ì´ ì˜¤ë©´, ì„ íƒ ê°€ëŠ¥í•œ ì–¸ë¡ ì‚¬ì™€ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
@app.get("/options", summary="ì„ íƒ ê°€ëŠ¥í•œ ì–¸ë¡ ì‚¬ ë° ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ")
def get_options():
    """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©ìì—ê²Œ ì„ íƒì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” APIì…ë‹ˆë‹¤."""
    return {"all_sources": all_sources, "categories": categories}

# '/analyze' ì£¼ì†Œë¡œ POST ìš”ì²­ì´ ì˜¤ë©´, ë‰´ìŠ¤ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.
@app.post("/analyze", summary="ë‰´ìŠ¤ ë¶„ì„ ìš”ì²­", response_model=Dict[str, List[EvaluatedArticle]])
async def analyze_news(request: AnalysisRequest):
    """ì‚¬ìš©ìë¡œë¶€í„° ì–¸ë¡ ì‚¬ ë° ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ë°›ì•„ ë‰´ìŠ¤ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ê°€ ìœ íš¨í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
    for cat in request.selected_categories:
        if cat not in categories:
            raise HTTPException(status_code=400, detail=f"'{cat}'ì€(ëŠ”) ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤.")

    final_results = {}
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    for main_category in request.selected_categories:
        for sub_category in categories[main_category]:
            # 1. ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘
            articles_to_evaluate = fetch_news(sub_category)
            if not articles_to_evaluate: continue

            # 2. ğŸ’¡ ìˆ˜ì§‘ëœ ëª¨ë“  ê¸°ì‚¬ì— ëŒ€í•´ GPT í‰ê°€ ì‘ì—…ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë™ì‹œì— ì‹¤í–‰
            evaluation_tasks = [gpt_evaluate_async(article) for article in articles_to_evaluate]
            evaluations = await asyncio.gather(*evaluation_tasks)

            # 3. ì›ë³¸ ê¸°ì‚¬ ì •ë³´ì™€ GPT í‰ê°€ ê²°ê³¼ë¥¼ í•©ì¹˜ê¸°
            evaluated_articles = []
            for article, evaluation in zip(articles_to_evaluate, evaluations):
                evaluated_articles.append(
                    EvaluatedArticle(
                        title=article['title'],
                        link=article['link'],
                        source=article['source'],
                        date=article['date'],
                        summary=evaluation['summary'],
                        reliability_grade=evaluation['reliability_grade'],
                        reliability_reason=evaluation['reliability_reason']
                    )
                )
            
            result_key = f"{main_category} - {sub_category}"
            final_results[result_key] = evaluated_articles

    if not final_results:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ë¶„ì„í•  ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return final_results

